"""
Gradio-based web interface for Whisper ASR service.
"""

import os
import tempfile
import time
from typing import Optional, Tuple, Generator

import gradio as gr

from transcriber import (
    WhisperTranscriber,
    SUPPORTED_LANGUAGES,
    MODEL_SIZES,
    get_gpu_info,
)
from youtube_downloader import (
    is_youtube_url,
    download_audio_with_progress,
    get_video_info,
)
from srt_utils import segments_to_srt, merge_segments


# Custom CSS with Roboto font
CUSTOM_CSS = """
@import url('https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap');

* {
    font-family: 'Roboto', sans-serif !important;
}

.gradio-container {
    font-family: 'Roboto', sans-serif !important;
}

.prose {
    font-family: 'Roboto', sans-serif !important;
}

textarea, input, button, select {
    font-family: 'Roboto', sans-serif !important;
}

.progress-bar-container {
    margin: 10px 0;
}
"""


# Global transcriber instance
transcriber: Optional[WhisperTranscriber] = None


def get_transcriber(
    model_size: str = "large-v3",
    use_vad: bool = True,
) -> WhisperTranscriber:
    """Get or create transcriber instance."""
    global transcriber
    
    if transcriber is None or transcriber.model_size != model_size:
        transcriber = WhisperTranscriber(
            model_size=model_size,
            device=os.environ.get("WHISPER_DEVICE", "cuda"),
            compute_type=os.environ.get("WHISPER_COMPUTE_TYPE", "float16"),
            use_vad=use_vad,
        )
    
    return transcriber


def format_progress_html(percent: int, message: str) -> str:
    """Generate HTML for progress bar."""
    return f"""
<div class="progress-bar-container">
    <div style="margin-bottom: 5px; font-weight: 500;">{message}</div>
    <div style="background-color: #e0e0e0; border-radius: 10px; height: 20px; overflow: hidden;">
        <div style="background: linear-gradient(90deg, #2196F3, #21CBF3); height: 100%; width: {percent}%; transition: width 0.3s ease; border-radius: 10px;"></div>
    </div>
    <div style="text-align: right; font-size: 12px; color: #666; margin-top: 3px;">{percent}%</div>
</div>
"""


def process_audio(
    audio_file: Optional[str],
    youtube_url: str,
    model_size: str,
    language: str,
    task: str,
    use_vad: bool,
    merge_subtitles: bool,
    max_chars: int,
) -> Generator[Tuple[str, str, Optional[str]], None, None]:
    """
    Process audio from file or YouTube URL.
    
    Yields:
        Tuple of (status message, SRT content, SRT file path)
    """
    audio_path = None
    temp_files = []
    video_title = "output"
    
    try:
        # Determine input source
        if youtube_url and youtube_url.strip():
            if not is_youtube_url(youtube_url):
                yield "âŒ ç„¡æ•ˆçš„ YouTube ç¶²å€", "", None
                return
            
            yield format_progress_html(5, "å–å¾—å½±ç‰‡è³‡è¨Š..."), "", None
            info = get_video_info(youtube_url)
            if info:
                video_title = info.get("title", "youtube_audio")
                yield format_progress_html(10, f"ä¸‹è¼‰ä¸­: {video_title[:40]}..."), "", None
            
            # Download audio
            audio_path, title = download_audio_with_progress(
                youtube_url,
                progress_callback=None,
            )
            
            yield format_progress_html(30, "ä¸‹è¼‰å®Œæˆ"), "", None
            
            if audio_path is None:
                yield "âŒ ä¸‹è¼‰å¤±æ•—ï¼Œè«‹ç¢ºèªç¶²å€æ˜¯å¦æ­£ç¢º", "", None
                return
            
            if title:
                video_title = title
            temp_files.append(audio_path)
            
        elif audio_file:
            audio_path = audio_file
            video_title = os.path.splitext(os.path.basename(audio_file))[0]
            yield format_progress_html(10, "éŸ³æª”å·²è¼‰å…¥"), "", None
        else:
            yield "âŒ è«‹ä¸Šå‚³éŸ³æª”æˆ–è¼¸å…¥ YouTube ç¶²å€", "", None
            return
        
        # Initialize transcriber
        yield format_progress_html(35, "è¼‰å…¥ Whisper æ¨¡å‹ä¸­..."), "", None
        trans = get_transcriber(model_size, use_vad)
        
        yield format_progress_html(40, "æ¨¡å‹è¼‰å…¥å®Œæˆï¼Œé–‹å§‹è½‰éŒ„..."), "", None
        
        # Transcribe with progress updates
        last_progress = [40]  # Use list to allow modification in nested function
        
        def transcribe_progress(pct, msg):
            # Map transcriber progress (0-100) to our range (40-85)
            mapped = 40 + int(pct * 0.45)
            last_progress[0] = mapped
        
        segments = trans.transcribe(
            audio_path,
            language=language if language != "auto" else None,
            task=task,
            progress_callback=transcribe_progress,
        )
        
        yield format_progress_html(85, "è½‰éŒ„å®Œæˆ"), "", None
        
        if not segments:
            yield "âš ï¸ æœªåµæ¸¬åˆ°èªéŸ³å…§å®¹", "", None
            return
        
        # Merge segments if requested
        if merge_subtitles:
            yield format_progress_html(90, "åˆä½µå­—å¹•æ®µè½..."), "", None
            segments = merge_segments(segments, max_chars=max_chars)
        
        # Generate SRT
        yield format_progress_html(95, "ç”Ÿæˆ SRT æª”æ¡ˆ..."), "", None
        srt_content = segments_to_srt(segments)
        
        # Save SRT file
        output_dir = "/app/outputs" if os.path.exists("/app/outputs") else tempfile.gettempdir()
        
        # Clean filename
        safe_title = "".join(c for c in video_title if c.isalnum() or c in " -_").strip()[:50]
        srt_filename = f"{safe_title}.srt"
        srt_path = os.path.join(output_dir, srt_filename)
        
        with open(srt_path, "w", encoding="utf-8") as f:
            f.write(srt_content)
        
        status = f"âœ… è½‰éŒ„å®Œæˆï¼å…± {len(segments)} å€‹å­—å¹•æ®µè½"
        yield status, srt_content, srt_path
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        yield f"âŒ éŒ¯èª¤: {str(e)}", "", None
    
    finally:
        # Cleanup temp files
        for f in temp_files:
            if f and os.path.exists(f):
                try:
                    os.unlink(f)
                except:
                    pass


def get_system_info() -> str:
    """Get system and GPU information."""
    info_lines = ["### ç³»çµ±è³‡è¨Š\n"]
    
    gpu_info = get_gpu_info()
    if gpu_info:
        info_lines.append(f"**GPU æ•¸é‡:** {len(gpu_info)}\n")
        for gpu in gpu_info:
            info_lines.append(
                f"- GPU {gpu['index']}: {gpu['name']} "
                f"({gpu['memory_total']:.1f} GB)"
            )
    else:
        info_lines.append("**GPU:** ç„¡å¯ç”¨ GPUï¼Œä½¿ç”¨ CPU æ¨¡å¼")
    
    return "\n".join(info_lines)


# Build Gradio interface
def create_interface() -> gr.Blocks:
    """Create and return Gradio interface."""
    
    with gr.Blocks(
        title="Whisper ASR å­—å¹•ç”Ÿæˆæœå‹™",
        theme=gr.themes.Soft(),
        css=CUSTOM_CSS,
    ) as app:
        
        gr.Markdown(
            """
            # ğŸ™ï¸ Whisper ASR å­—å¹•ç”Ÿæˆæœå‹™
            
            ä¸Šå‚³éŸ³æª”ã€å½±ç‰‡ï¼Œæˆ–è¼¸å…¥ YouTube ç¶²å€ï¼Œè‡ªå‹•ç”Ÿæˆ SRT å­—å¹•æª”ã€‚
            """
        )
        
        with gr.Row():
            # Left column: Input
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“¥ è¼¸å…¥")
                
                audio_input = gr.Audio(
                    label="ä¸Šå‚³éŸ³æª”æˆ–å½±ç‰‡",
                    type="filepath",
                    sources=["upload", "microphone"],
                )
                
                gr.Markdown("**æˆ–**")
                
                youtube_input = gr.Textbox(
                    label="YouTube ç¶²å€",
                    placeholder="https://www.youtube.com/watch?v=...",
                )
                
                gr.Markdown("### âš™ï¸ è¨­å®š")
                
                with gr.Row():
                    model_dropdown = gr.Dropdown(
                        choices=MODEL_SIZES,
                        value=os.environ.get("WHISPER_MODEL", "large-v3"),
                        label="æ¨¡å‹å¤§å°",
                    )
                    
                    language_dropdown = gr.Dropdown(
                        choices=list(SUPPORTED_LANGUAGES.keys()),
                        value="auto",
                        label="èªè¨€",
                    )
                
                with gr.Row():
                    task_radio = gr.Radio(
                        choices=[
                            ("è½‰éŒ„ (Transcribe)", "transcribe"),
                            ("ç¿»è­¯æˆè‹±æ–‡ (Translate)", "translate"),
                        ],
                        value="transcribe",
                        label="åŠŸèƒ½",
                    )
                
                with gr.Row():
                    use_vad_checkbox = gr.Checkbox(
                        value=True,
                        label="ä½¿ç”¨ VAD èªéŸ³åµæ¸¬",
                    )
                    merge_checkbox = gr.Checkbox(
                        value=True,
                        label="åˆä½µçŸ­å­—å¹•",
                    )
                
                max_chars_slider = gr.Slider(
                    minimum=40,
                    maximum=120,
                    value=80,
                    step=10,
                    label="æ¯è¡Œæœ€å¤§å­—æ•¸",
                    visible=True,
                )
                
                process_btn = gr.Button(
                    "ğŸš€ é–‹å§‹è½‰éŒ„",
                    variant="primary",
                    size="lg",
                )
            
            # Right column: Output
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“¤ è¼¸å‡º")
                
                status_text = gr.HTML("ç­‰å¾…è¼¸å…¥...")
                
                srt_output = gr.Textbox(
                    label="SRT å­—å¹•å…§å®¹",
                    lines=20,
                    max_lines=30,
                )
                
                srt_file = gr.File(
                    label="ä¸‹è¼‰ SRT æª”æ¡ˆ",
                )
        
        # System info
        with gr.Accordion("ç³»çµ±è³‡è¨Š", open=False):
            system_info = gr.Markdown(get_system_info())
        
        # Language mapping display
        with gr.Accordion("æ”¯æ´èªè¨€åˆ—è¡¨", open=False):
            lang_info = "\n".join(
                f"- `{code}`: {name}"
                for code, name in SUPPORTED_LANGUAGES.items()
            )
            gr.Markdown(lang_info)
        
        # Event handlers
        process_btn.click(
            fn=process_audio,
            inputs=[
                audio_input,
                youtube_input,
                model_dropdown,
                language_dropdown,
                task_radio,
                use_vad_checkbox,
                merge_checkbox,
                max_chars_slider,
            ],
            outputs=[status_text, srt_output, srt_file],
        )
        
        # Clear YouTube when audio uploaded and vice versa
        audio_input.change(
            fn=lambda x: "" if x else gr.update(),
            inputs=[audio_input],
            outputs=[youtube_input],
        )
        
        youtube_input.change(
            fn=lambda x: None if x else gr.update(),
            inputs=[youtube_input],
            outputs=[audio_input],
        )
        
        # Toggle max_chars visibility based on merge checkbox
        merge_checkbox.change(
            fn=lambda x: gr.update(visible=x),
            inputs=[merge_checkbox],
            outputs=[max_chars_slider],
        )
    
    return app


def main():
    """Main entry point."""
    # Pre-load model if specified
    default_model = os.environ.get("WHISPER_MODEL", "large-v3")
    preload = os.environ.get("PRELOAD_MODEL", "false").lower() == "true"
    
    if preload:
        print(f"Pre-loading model: {default_model}")
        get_transcriber(default_model)
    
    # Create and launch app
    app = create_interface()
    
    app.launch(
        server_name=os.environ.get("GRADIO_SERVER_NAME", "0.0.0.0"),
        server_port=int(os.environ.get("GRADIO_SERVER_PORT", 7860)),
        share=False,
        show_error=True,
    )


if __name__ == "__main__":
    main()

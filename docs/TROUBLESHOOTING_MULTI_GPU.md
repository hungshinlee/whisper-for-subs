# å¤š GPU åŠŸèƒ½å•é¡Œè¨ºæ–·èˆ‡ä¿®å¾©

## ğŸ“Š ç•¶å‰ç‹€æ³åˆ†æ

æ ¹æ“šä½ çš„æ—¥èªŒï¼š

```
Initialized ParallelWhisperTranscriber with 4 GPUs: [0, 1, 2, 3]
Loading Whisper model: large-v3-turbo on cuda (é‡è¤‡ 19 æ¬¡)
Warning: 19 segments failed to transcribe
```

### âœ… æ­£å¸¸çš„éƒ¨åˆ†
1. **å¤š GPU åŠŸèƒ½å·²å•Ÿå‹•** - 4 å¼µ GPU æ­£ç¢ºè­˜åˆ¥
2. **æ¨¡å‹è¼‰å…¥ 19 æ¬¡** - é€™æ˜¯**æ­£å¸¸è¡Œç‚º**ï¼ˆæ¯å€‹å­é€²ç¨‹è™•ç†ä¸€å€‹æ®µè½æ™‚è¼‰å…¥æ¨¡å‹ï¼‰
3. **CUDA å’Œ Gradio** - éƒ½æ­£å¸¸é‹ä½œ

### âš ï¸ å•é¡Œï¼š19 å€‹æ®µè½è½‰éŒ„å¤±æ•—

å¯èƒ½çš„åŸå› ï¼š
1. **éŸ³è¨Šæ®µè½å¤ªçŸ­** - VAD åˆ‡åˆ†ç”¢ç”Ÿäº†å¾ˆå¤šæ¥µçŸ­çš„æ®µè½
2. **æš«å­˜æª”æ¡ˆå•é¡Œ** - å­é€²ç¨‹é–“å¯èƒ½æœ‰æª”æ¡ˆè¡çª
3. **è®Šæ•¸æœªåˆå§‹åŒ–** - `temp_path` åœ¨ç•°å¸¸æ™‚å¯èƒ½æœªå®šç¾©

---

## ğŸ”§ ä¿®å¾©æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: æ›´æ–° parallel_transcriber.pyï¼ˆæ¨è–¦ï¼‰

æˆ‘å·²ç¶“ç‚ºä½ æº–å‚™äº†æ”¹é€²ç‰ˆæœ¬ï¼ŒåŒ…å«ï¼š

1. **æ›´å¥½çš„éŒ¯èª¤è™•ç†**
   - è©³ç´°çš„éŒ¯èª¤æ—¥èªŒå’Œ traceback
   - æª¢æŸ¥éŸ³è¨Šæ®µè½é•·åº¦
   - å®‰å…¨çš„æš«å­˜æª”æ¡ˆæ¸…ç†

2. **éæ¿¾æ¥µçŸ­æ®µè½**
   - è‡ªå‹•è·³é < 100ms çš„æ®µè½
   - æ¸›å°‘ç„¡æ•ˆçš„è½‰éŒ„å˜—è©¦

3. **é€²åº¦æ—¥èªŒ**
   - æ¯å€‹æ®µè½çš„è™•ç†ç‹€æ…‹
   - æ¸…æ¥šæ¨™ç¤º GPU ä½¿ç”¨æƒ…æ³

å°‡ä»¥ä¸‹æ”¹é€²ç‰ˆæœ¬çš„ä»£ç¢¼è¤‡è£½åˆ°å®¹å™¨ä¸­ï¼š

```python
# æ”¹é€²çš„ transcribe_segment_on_gpu å‡½æ•¸
def transcribe_segment_on_gpu(args: tuple) -> Dict:
    """
    Transcribe a single audio segment on a specific GPU.
    """
    (
        segment_idx, audio_data, start_time, end_time,
        gpu_id, model_size, language, task, compute_type,
    ) = args
    
    temp_path = None  # åˆå§‹åŒ–è®Šæ•¸
    os.environ["CUDA_VISIBLE_DEVICES"] = str(gpu_id)
    
    try:
        # é©—è­‰éŸ³è¨Šæ•¸æ“š
        if len(audio_data) == 0:
            raise ValueError(f"Segment {segment_idx}: Empty audio data")
        
        duration = end_time - start_time
        
        # éæ¿¾å¤ªçŸ­çš„æ®µè½
        if duration < 0.1:  # å°æ–¼ 100ms
            print(f"Warning: Segment {segment_idx} too short ({duration:.2f}s), skipping")
            return {
                "segment_idx": segment_idx,
                "success": True,
                "segments": [],
                "gpu_id": gpu_id,
                "duration": duration,
                "skipped": True,
            }
        
        # å‰µå»ºæš«å­˜æª”æ¡ˆ
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
            temp_path = temp_file.name
            sf.write(temp_path, audio_data, 16000)
        
        print(f"[GPU {gpu_id}] Processing segment {segment_idx} ({duration:.1f}s)")
        
        # åˆå§‹åŒ–ä¸¦è½‰éŒ„
        transcriber = WhisperTranscriber(
            model_size=model_size,
            device="cuda",
            compute_type=compute_type,
            use_vad=False,
        )
        
        segments = transcriber.transcribe(
            temp_path,
            language=language,
            task=task,
            progress_callback=None,
        )
        
        # èª¿æ•´æ™‚é–“æˆ³
        adjusted_segments = []
        for seg in segments:
            adjusted_segments.append({
                "start": start_time + seg["start"],
                "end": start_time + seg["end"],
                "text": seg["text"],
            })
        
        print(f"[GPU {gpu_id}] âœ“ Segment {segment_idx}: {len(adjusted_segments)} texts")
        
        return {
            "segment_idx": segment_idx,
            "success": True,
            "segments": adjusted_segments,
            "gpu_id": gpu_id,
            "duration": duration,
        }
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"[GPU {gpu_id}] âœ— ERROR in segment {segment_idx}: {str(e)}")
        print(f"[GPU {gpu_id}] Traceback:\n{error_detail}")
        
        return {
            "segment_idx": segment_idx,
            "success": False,
            "error": str(e),
            "error_detail": error_detail,
            "gpu_id": gpu_id,
        }
    
    finally:
        # å®‰å…¨æ¸…ç†æš«å­˜æª”æ¡ˆ
        if temp_path and os.path.exists(temp_path):
            try:
                os.unlink(temp_path)
            except Exception as e:
                print(f"Warning: Could not delete {temp_path}: {e}")
```

### æ–¹æ¡ˆ 2: èª¿æ•´ VAD åƒæ•¸ï¼ˆè‡¨æ™‚æªæ–½ï¼‰

å¦‚æœç„¡æ³•ç«‹å³æ›´æ–°ä»£ç¢¼ï¼Œå¯ä»¥èª¿æ•´ VAD åƒæ•¸ä¾†æ¸›å°‘æ¥µçŸ­æ®µè½ï¼š

åœ¨ `app.py` æˆ– `parallel_transcriber.py` ä¸­ï¼š

```python
# å¢åŠ æœ€å°æ®µè½é•·åº¦
para_trans = ParallelWhisperTranscriber(
    model_size=model_size,
    compute_type=compute_type,
    gpu_ids=gpu_ids,
    vad_threshold=0.5,  # å¯ä»¥ç¨å¾®æé«˜åˆ° 0.6
)

segments = para_trans.transcribe_parallel(
    audio_path,
    language=language,
    task=task,
    min_segment_duration=15.0,  # å¾ 10s å¢åŠ åˆ° 15s
    max_segment_duration=45.0,  # å¾ 60s æ¸›å°‘åˆ° 45s
)
```

---

## ğŸ” è¨ºæ–·æ­¥é©Ÿ

### 1. æª¢æŸ¥è©³ç´°éŒ¯èª¤

é€²å…¥å®¹å™¨æŸ¥çœ‹æ›´å¤šç´°ç¯€ï¼š

```bash
# æŸ¥çœ‹å®Œæ•´æ—¥èªŒ
docker logs whisper-for-subs --tail=100

# æˆ–å³æ™‚ç›£æ§
docker logs -f whisper-for-subs 2>&1 | grep -E "ERROR|Warning|GPU"
```

### 2. æ¸¬è©¦å–®ä¸€æ®µè½è™•ç†

```bash
# é€²å…¥å®¹å™¨
docker exec -it whisper-for-subs bash

# æ¸¬è©¦åŸºæœ¬è½‰éŒ„åŠŸèƒ½
python -c "
from transcriber import WhisperTranscriber
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0'
t = WhisperTranscriber('large-v3-turbo', 'cuda', 'float16', False)
print('âœ“ Transcriber loaded successfully')
"
```

### 3. æª¢æŸ¥ GPU è¨˜æ†¶é«”

```bash
# ç›£æ§ GPU ä½¿ç”¨æƒ…æ³
watch -n 1 nvidia-smi

# æŸ¥çœ‹æ˜¯å¦æœ‰è¨˜æ†¶é«”ä¸è¶³
nvidia-smi --query-gpu=memory.used,memory.total --format=csv
```

### 4. æ¸¬è©¦ä¸åŒéŸ³è¨Š

```bash
# ç”¨è¼ƒçŸ­çš„æ¸¬è©¦éŸ³è¨Šï¼ˆ5-10 åˆ†é˜ï¼‰
# è§€å¯Ÿæ˜¯å¦ä»æœ‰å¤±æ•—
```

---

## ğŸ“‹ å¿«é€Ÿä¿®å¾©æ¸…å–®

### ç«‹å³å¯åšï¼š

1. **é™ä½å¤±æ•—ç‡**
   ```bash
   # åœ¨ docker-compose.yml ä¸­èª¿æ•´åƒæ•¸
   environment:
     - WHISPER_COMPUTE_TYPE=float16  # ç¢ºèªä½¿ç”¨ float16
   
   # é‡å•Ÿå®¹å™¨
   docker compose restart
   ```

2. **å¢åŠ æ—¥èªŒç´šåˆ¥**
   ```bash
   # åœ¨ app.py é–‹é ­åŠ å…¥
   import logging
   logging.basicConfig(level=logging.DEBUG)
   ```

3. **æ¸¬è©¦å–® GPU æ¨¡å¼**
   ```bash
   # æš«æ™‚å–æ¶ˆå‹¾é¸å¤š GPU é¸é …
   # çœ‹çœ‹å–® GPU æ˜¯å¦æ­£å¸¸
   ```

### é•·æœŸæ”¹å–„ï¼š

1. **æ›´æ–°ä»£ç¢¼** - ä½¿ç”¨ä¸Šé¢çš„æ”¹é€²ç‰ˆæœ¬
2. **å„ªåŒ– VAD åƒæ•¸** - æ¸›å°‘æ¥µçŸ­æ®µè½
3. **ç›£æ§ç³»çµ±** - åŠ å…¥ Prometheus + Grafana

---

## ğŸ¯ é æœŸçµæœ

ä¿®å¾©å¾Œæ‡‰è©²çœ‹åˆ°ï¼š

```
âœ… å¥½çš„æ—¥èªŒï¼š
[GPU 0] Processing segment 0 (12.3s)
[GPU 1] Processing segment 1 (15.7s)
[GPU 2] Processing segment 2 (11.2s)
[GPU 3] Processing segment 3 (18.4s)
[GPU 0] âœ“ Segment 0: 8 texts
[GPU 1] âœ“ Segment 1: 12 texts
Warning: Segment 4 too short (0.05s), skipping  # è‡ªå‹•è·³é
[GPU 2] âœ“ Segment 2: 10 texts
...
Complete! 127 segments | Speed: 28.3x realtime
```

---

## ğŸ’¡ æš«æ™‚çš„å·¥ä½œæ–¹æ¡ˆ

å¦‚æœéœ€è¦ç«‹å³ä½¿ç”¨ï¼Œå¯ä»¥ï¼š

1. **ä½¿ç”¨å–® GPU æ¨¡å¼**
   - å–æ¶ˆå‹¾é¸å¤š GPU é¸é …
   - é›–ç„¶è¼ƒæ…¢ä½†æ›´ç©©å®š

2. **ä½¿ç”¨è¼ƒçŸ­éŸ³è¨Š**
   - å…ˆæ¸¬è©¦ 5-15 åˆ†é˜çš„éŸ³è¨Š
   - ç¢ºèªåŸºæœ¬åŠŸèƒ½æ­£å¸¸

3. **æ‰‹å‹•åˆ†æ®µè™•ç†**
   - å°‡é•·éŸ³è¨Šåˆ†æˆå¤šå€‹æª”æ¡ˆ
   - åˆ†åˆ¥ä¸Šå‚³è™•ç†

---

## ğŸ“ éœ€è¦æ›´å¤šå¹«åŠ©ï¼Ÿ

å¦‚æœå•é¡ŒæŒçºŒï¼š

1. æä¾›å®Œæ•´çš„éŒ¯èª¤æ—¥èªŒï¼ˆç´„ 200 è¡Œï¼‰
2. èªªæ˜æ¸¬è©¦çš„éŸ³è¨Šç‰¹æ€§ï¼ˆé•·åº¦ã€ä¾†æºï¼‰
3. åŸ·è¡Œè¨ºæ–·æŒ‡ä»¤ä¸¦åˆ†äº«çµæœ

---

**ä¸‹ä¸€æ­¥**ï¼šå»ºè­°å…ˆåŸ·è¡Œè¨ºæ–·æ­¥é©Ÿ 1-3ï¼Œç¢ºèªå…·é«”çš„éŒ¯èª¤åŸå› ï¼Œç„¶å¾Œæ±ºå®šä½¿ç”¨å“ªå€‹ä¿®å¾©æ–¹æ¡ˆã€‚
